# Audio Model with User Transcription Display

## âœ… Current Implementation

Switched back to using **`gpt-4o-mini-audio-preview`** (audio model) for voice input, while still showing the user's transcribed text in the chatbox.

---

## ğŸ¯ Architecture

### **Voice Input Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. USER SPEAKS                                             â”‚
â”‚     User holds button and records voice                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. DUAL STT (for display + generation)                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚ a) Whisper API (for UI display)             â”‚      â”‚
â”‚     â”‚    - Transcribes user's speech               â”‚      â”‚
â”‚     â”‚    - Returns: "What user said"               â”‚      â”‚
â”‚     â”‚    - Cost: ~$0.0001                          â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚ b) Audio Model (for generation)             â”‚      â”‚
â”‚     â”‚    - gpt-4o-mini-audio-preview               â”‚      â”‚
â”‚     â”‚    - Processes voice + generates response    â”‚      â”‚
â”‚     â”‚    - Cost: ~$0.0003                          â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. DISPLAY IN CHATBOX                                      â”‚
â”‚     User: "[Transcribed text from Whisper]"                â”‚
â”‚     AI: "[Response from audio model]"                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. TEXT-TO-SPEECH                                          â”‚
â”‚     AI text â†’ OpenAI TTS â†’ Audio output                    â”‚
â”‚     Cost: ~$0.0072                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Cost Breakdown

### **Per Voice Response:**
| Component | API | Cost | Purpose |
|-----------|-----|------|---------|
| **STT (Display)** | Whisper | $0.0001 | Show user's text in chatbox |
| **STT + Text Gen** | Audio Model | $0.0003 | Process voice + generate response |
| **TTS** | OpenAI TTS | $0.0072 | Convert AI text to audio |
| **Total** | - | **$0.0076** | Per voice response |

**Previous (streaming approach):** $0.0075  
**Current (audio model):** $0.0076  
**Difference:** +$0.0001 (negligible)

---

## ğŸ”„ Why Dual STT?

### **Problem:**
The `gpt-4o-mini-audio-preview` model doesn't return the user's transcription in the API response.

### **Solution:**
1. **Whisper API** transcribes user speech â†’ Display in chatbox
2. **Audio Model** processes voice directly â†’ Generates AI response

### **Trade-offs:**
| Approach | Cost | Speed | Pros | Cons |
|----------|------|-------|------|------|
| **Whisper + Text Model** | $0.0073 | Slower | Streamable, modular | 2 API calls |
| **Audio Model only** | $0.0003 | Faster | Single call | No user transcription |
| **Both (Current)** | $0.0076 | Fast | Best UX | Slight overlap |

---

## âš¡ Performance

### **Timing:**
| Phase | Time | Details |
|-------|------|---------|
| **Recording** | ~1-3s | User speaks |
| **Transcription (Whisper)** | ~500ms | Parallel with audio model |
| **Audio Model Processing** | ~1-2s | STT + text generation |
| **Display User Message** | Instant | After transcription |
| **Display AI Response** | Instant | After audio model |
| **TTS Generation** | ~1-2s | Parallel, non-blocking |
| **Audio Playback** | ~2-4s | Starts when ready |

**Total perceived time:** ~2-4s (user sees text ~1-2s)

---

## ğŸ¯ User Experience

### **What User Sees:**

```
[User holds button and speaks]
â†“
[Loading: "Processing your voice..."]
â†“
User: "Tell me about this artifact"
      (Appears ~1-2s after speaking)
â†“
AI: "This artifact is from the Ming Dynasty..."
    (Appears immediately after user message)
â†“
ğŸ”Š [Audio plays automatically]
```

---

## ğŸ”§ Technical Details

### **Frontend (MobileAIAssistant.vue):**

```typescript
async function getAIResponseWithVoice(voiceInput) {
  // Call chat-with-audio with audio model
  // Edge Function will:
  // 1. Transcribe with Whisper (for display)
  // 2. Process with audio model (for generation)
  // 3. Return both transcription and response
  
  const { data } = await supabase.functions.invoke('chat-with-audio', {
    body: {
      voiceInput: voiceInput,
      modalities: ['text']  // Text only output (no audio from model)
    }
  })
  
  // Display user's transcription
  addUserMessage(data.userTranscription)
  
  // Display AI's response
  addAssistantMessage(data.message.content)
  
  // Generate TTS audio
  generateAndPlayTTS(data.message.content)
}
```

### **Backend (chat-with-audio Edge Function):**

```typescript
// Always transcribe with Whisper for UI display
const userTranscription = await transcribeWithWhisper(voiceInput)

// Use audio model for generation (based on STT mode)
if (sttMode === 'audio-model') {
  // Send voice input to audio model
  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini-audio-preview',
    messages: [...history, { 
      role: 'user',
      content: [{ type: 'input_audio', input_audio: voiceInput }]
    }]
  })
}

// Return both transcription and response
return {
  userTranscription,  // For UI display
  message: response.message  // AI's response
}
```

---

## ğŸ“Š Comparison

### **vs. Previous Streaming Approach:**

| Aspect | Audio Model (Current) | Streaming Approach | Winner |
|--------|---------------------|-------------------|---------|
| **Cost** | $0.0076 | $0.0075 | Streaming (-$0.0001) |
| **Speed** | ~2-4s | ~2-4s | Tie |
| **Text Display** | All at once | Progressive | Streaming âœ¨ |
| **API Calls** | 2 (Whisper + Audio Model) | 2 (Whisper + Text Model) | Tie |
| **Complexity** | Simple | More complex | Audio Model |
| **User Transcription** | âœ… Yes | âœ… Yes | Tie |

**Note:** Streaming provides slightly better UX with progressive text, but audio model is simpler.

---

## ğŸ¯ Configuration

### **Current Settings:**

```toml
# supabase/config.toml

# STT Mode (using audio-model)
OPENAI_STT_MODE = "audio-model"

# Audio Model (for STT + generation)
OPENAI_AUDIO_MODEL = "gpt-4o-mini-audio-preview"

# Whisper (for transcription display)
OPENAI_WHISPER_MODEL = "whisper-1"

# TTS
OPENAI_TTS_MODEL = "tts-1"
OPENAI_TTS_VOICE = "alloy"
```

---

## âœ… Summary

**Current Implementation:**
- âœ… Uses `gpt-4o-mini-audio-preview` (audio model)
- âœ… Shows user's transcribed text in chatbox
- âœ… Displays AI's response immediately
- âœ… Generates and plays TTS audio
- âœ… Cost: $0.0076 per voice response

**Flow:**
```
Voice â†’ Whisper (transcribe for display) â†’ Audio Model (generate response) â†’ Display both â†’ TTS â†’ Audio
```

**Trade-off:** Slightly more expensive (+$0.0001) than pure text approach, but uses audio model as requested.

**Alternative:** If you want streaming text + lower cost, switch to `OPENAI_STT_MODE=whisper` (saves $0.0003 but adds latency).

